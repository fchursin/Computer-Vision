# Computer-Vision

## Author
- Created by: Fedor Chursin
- Contact: fedorchursinsk@gmail.com
- GitHub: fchursin

## Overview

Welcome to the ML Learning Project repository! This project is focused on building and understanding Convolutional Neural Networks (CNNs) for computer vision tasks, with a strong emphasis on Responsible AI practices. In this project, we aim to create a working prototype of a CNN model that predicts different types of food based on input images. We will also apply various Explainable AI methods to interpret the model's decisions and assess its fairness.

## Project Contents

This repository contains the following files and folders:

### 1. `CNN-Computer-Vision-Model-LifeCycle.ipynb`

This Jupyter Notebook guides you through the entire lifecycle of a CNN model for food image classification. It covers the following key steps:
- Data preprocessing
- Data augmentation
- CNN model architecture design and training
- CNN model tuning
- Transfer learning
- Application of Explainable AI techniques to the model
- Performance metrics evaluation
- Error analysis for the model

### 2. `Responsible-AI.ipynb`

In this Jupyter Notebook, we delve into the responsible AI aspects of the project. It includes information on:
- Identifying biases in the data
- An image scraping script for data collection
- Fairness metrics assessment
- Application of Explainable AI methods, such as Lime, GradCam, and Oculus Sensetivity, to the models for interpretability.

### 3. `Proof_of_concept.pdf`

This file contains a presentation summarizing the proof of concept for the CNN model and real-life applications. It provides an overview of the project's goals, methods, and results.

## Tools Used

The primary tools and technologies used for this project are:
- Python
- Libraries for computer vision
- Explainable AI methods and libraries

## Project Goal

The primary goal of this project is to create a functional prototype of a CNN model capable of accurately classifying different types of food based on input images. Additionally, we aim to make the model interpretable by applying various Explainable AI methods to elucidate how the model makes decisions. Lastly, we intend to showcase the real-life applications of this model in a proof of concept.

## Author

- Name: Fedor Chursin
- Email: fedorchursinsk@gmail.com

Thank you for exploring this ML Learning Project! Feel free to reach out to the author if you have any questions or feedback.
